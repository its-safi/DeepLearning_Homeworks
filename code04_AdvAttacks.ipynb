{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code04_learning_PyTorch_04_AdvAttacks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d71845ab3ce6492fa6103b111cd36406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ba2d85f5d8740b88564dc98a636fcb3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c399424eaf248e8a787d3cb8096fb40",
              "IPY_MODEL_e0fd3c82575b428fb4d92171aba05335",
              "IPY_MODEL_bb83225d303044cca5d786c3c138d690"
            ]
          }
        },
        "8ba2d85f5d8740b88564dc98a636fcb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c399424eaf248e8a787d3cb8096fb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85c08152c01c4941815539c88819e689",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67da5f0dcfa74e22bd6439dcff6c0de8"
          }
        },
        "e0fd3c82575b428fb4d92171aba05335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_170fa6cd78c2425f8ebdfa9eba50f2f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_390768d30e8a448bad7fe036a52fbfa0"
          }
        },
        "bb83225d303044cca5d786c3c138d690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3588b2b0783143ed955967e17c5a01ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 79875999.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9268b2a79de4e9f9eb8fa3ede039a4a"
          }
        },
        "85c08152c01c4941815539c88819e689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67da5f0dcfa74e22bd6439dcff6c0de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "170fa6cd78c2425f8ebdfa9eba50f2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "390768d30e8a448bad7fe036a52fbfa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3588b2b0783143ed955967e17c5a01ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9268b2a79de4e9f9eb8fa3ede039a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/its-safi/DeepLearning_Homeworks/blob/main/code04_AdvAttacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adversarial Attacks**\n",
        "\n",
        "One of the key functionalities that Pytorch provides us, is differentiation: with the right commands we can obtain the partial derivative of any output with respect to any input.\n",
        "\n",
        "Where as when we train, we use this to update the internal weight of the neural network, now we can use this to try to perturb the input image. This is called an *adversarial attack*. Note that unlike *poisoning attacks*, adversarial attacks are attacks on testing images, not training images.\n",
        "\n",
        "We use these ideas to construct one specific kind of adversarial attack called a \"Fast Gradient Sign Method\", or FGSM. \n",
        "\n",
        "We create FGSM attacks on CIFAR 10, building off of what we've done in Notebooks 2 and 3, and also from this tutorial:\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/fgsm_tutorial.html"
      ],
      "metadata": {
        "id": "-YWQEGiaafg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "PzY4n_hKeyA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6neBzF4aZRE",
        "outputId": "bb1334c9-c5ff-4596-aa14-4cb64d8df0eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"\n",
        "We define the same CIFAR10 model we've been working with, \n",
        "and load the model we've saved, as in Notebook 2b.\n",
        "\"\"\"\n",
        "\n",
        "# Define the Conv Net\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1: Saving and Loading Files\n",
        "\n",
        "Go back to your previous notebook, and train your best CIFAR10 network. Then save it using the command:\n",
        "\n",
        "torch.save(model2.state_dict(), './drive/MyDrive/Colab\\ Notebooks')\n",
        "\n",
        "(choose whatever path you like). \n",
        "\n",
        "Make sure that ConvNet defined above has the same structure as your favorite model that you saved. Then modify the command below as appropriate, to initialize a new model of the same structure, and then load in the saved weights.\n",
        "\n"
      ],
      "metadata": {
        "id": "udzLU-bkVVIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now load your saved model\n",
        "# Have to mount google drive before giving this command\n",
        "model = ConvNet()\n",
        "model.load_state_dict(torch.load('./drive/MyDrive/Colab\\ Notebooks'))"
      ],
      "metadata": {
        "id": "DuPOZzy0Vmy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now giving the same commands we've seen in previous notebooks\n",
        "# we load the data and define the training and validation\n",
        "# data loaders we need. \n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "# the tutorial calls the dataloader twice -- this code defines a function\n",
        "# that will do this for the train/test data.\n",
        "\n",
        "def fetch_dataloader(batch_size, transform=None, is_train=True):\n",
        "    \"\"\"\n",
        "    Loads data from disk and returns a data_loader.\n",
        "    A DataLoader is similar to a list of (image, label) tuples.\n",
        "    It is used to avoid loading all of the data into memory.\n",
        "    This is particularly useful for large data sets.\n",
        "    \"\"\"\n",
        "    data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "    # Custom train/val split.\n",
        "    indices = [i for i in range(len(data)) if (i%10 > 0) == is_train]\n",
        "\n",
        "    data = torch.utils.data.Subset(data, indices)\n",
        "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    return loader\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "val_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "data_train = fetch_dataloader(batch_size, train_transform, is_train=True)\n",
        "data_val = fetch_dataloader(batch_size, val_transform, is_train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "d71845ab3ce6492fa6103b111cd36406",
            "8ba2d85f5d8740b88564dc98a636fcb3",
            "2c399424eaf248e8a787d3cb8096fb40",
            "e0fd3c82575b428fb4d92171aba05335",
            "bb83225d303044cca5d786c3c138d690",
            "85c08152c01c4941815539c88819e689",
            "67da5f0dcfa74e22bd6439dcff6c0de8",
            "170fa6cd78c2425f8ebdfa9eba50f2f1",
            "390768d30e8a448bad7fe036a52fbfa0",
            "3588b2b0783143ed955967e17c5a01ba",
            "c9268b2a79de4e9f9eb8fa3ede039a4a"
          ]
        },
        "id": "wixzZSRXesXB",
        "outputId": "1844492c-05e3-4127-b94b-383a8562aba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d71845ab3ce6492fa6103b111cd36406",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's again check how good our model is on all the data\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in data_val:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BHmJ8ZhgGfO",
        "outputId": "cef123b6-13a1-48ab-d6ed-63f4299b3dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 60 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # if eps == 0 just return the image\n",
        "    #if (eps==0): \n",
        "    #  return image\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    # Adding clipping to maintain [-1,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, -1, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "CkqS67ekgSxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test( model, device, test_loader, epsilon ):\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        # Send the data and label to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass the data through the model\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # Zero all existing gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                #adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                perturbed_data = perturbed_data / 2 + 0.5     # unnormalize\n",
        "                npPD = perturbed_data.detach().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), npPD) )\n",
        "        else:\n",
        "            # Save some adv examples for visualization later\n",
        "            if len(adv_examples) < 5:\n",
        "                perturbed_data = perturbed_data / 2 + 0.5     # unnormalize\n",
        "                npPD = perturbed_data.detach().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), npPD) )\n",
        "                #adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                #adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adv_examples"
      ],
      "metadata": {
        "id": "pAAXIagdzUSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We set the list of epsilons for the attack\n",
        "#epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "epsilons = [0, .05]\n",
        "# We set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Now we run the attack and see the accuracy\n",
        "accuracies = []\n",
        "examples = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    acc, ex = test(model, device, data_val, eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvViA9sDzgyI",
        "outputId": "d4d69d0a-988e-43ce-dbde-41636916ec33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epsilon: 0\tTest Accuracy = 3038 / 5000 = 0.6076\n",
            "Epsilon: 0.05\tTest Accuracy = 533 / 5000 = 0.1066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2: Print some images of successful attacks, \n",
        "\n",
        "i.e., some images that were correctly classified pre-attack, and then incorrectly classified."
      ],
      "metadata": {
        "id": "ehwsS7vuWf9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3 (Optional):\n",
        "\n",
        "Try creating targeted attacks. For example, see for a given $\\epsilon$ what fraction of the data you can change into a particular label, as opposed to just the wrong label. For example, what fraction can you turn into a frog?"
      ],
      "metadata": {
        "id": "5EFkd55CWyAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cIsuJA7bWpgA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}